{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/6TP5sl+4QvYZ7hLx7r9I"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Brain Tumor Detection Using DL"
      ],
      "metadata": {
        "id": "ysbzzMScvPzP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "zipfile module is used to provide tool for working on zip file\n",
        "\n",
        "with is a keyword to open the zipfile in r (read) mode\n",
        "\n",
        "\"as zip\" assigns the opened Zip file object to zip variable\n",
        "extract all extracts all the contents of zip file"
      ],
      "metadata": {
        "id": "RP7YnxSYvbap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "dataset = \"/content/Brain_Tumor_Dataset.zip\"\n",
        "with ZipFile(dataset, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Done\")"
      ],
      "metadata": {
        "id": "sd4a6sg_Qc0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1822065d-f9e1-45b3-e773-6a5e54c1bbe0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numpy is a module with the help of which we can perform all the array operations\n",
        "\n",
        "Matplotlib.pyplot is used for 2D plotting and vizualizing data\n",
        "\n",
        "OS allows use functions related to working directories\n",
        "\n",
        "Shutil helps use to copy and remove files from or to a folder"
      ],
      "metadata": {
        "id": "AUMsW4JavlPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "import shutil\n",
        "import glob"
      ],
      "metadata": {
        "id": "JJusQdg9pQYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROOT_DIR is used to set the path of of our dataset\n",
        "\n",
        "images is a dictionary used to store the counts of Tumor and Healthy images\n",
        "\n",
        "os.listdir(ROOT_DIR) returns a list of all the subdirectories present in our dataset for example here Tumor and Healthy are subdirectories\n",
        "\n",
        "os.path.join is used to construct a full path from the dataset to the subdirectories\n",
        "\n",
        "len function counts the number of images and stores them corresponding to respective KEY value ie dir/subdirectories"
      ],
      "metadata": {
        "id": "aEtnZhgevo8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR='/content/Brain_Tumor_Dataset'\n",
        "images={}\n",
        "for dir in os.listdir(ROOT_DIR):\n",
        "    images[dir]=len(os.listdir(os.path.join(ROOT_DIR,dir)))"
      ],
      "metadata": {
        "id": "zgq4y7eWpc8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KwDp_Hhp1p_",
        "outputId": "2cfbc68b-87e0-4e20-e31d-029c20814c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('Tumor', 3516), ('Healthy', 1950)])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions of os.listdir()"
      ],
      "metadata": {
        "id": "f0eqh4OgvwVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/Brain_Tumor_Dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC06_civqOJa",
        "outputId": "357bd97f-72cd-47be-b4d5-eda20903865c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tumor', 'Healthy']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check if the train and test directory already exists\n",
        "\n",
        "if not create both the directories using mkdir (make directories)\n",
        "\n",
        "for each directory (test and train) make a subdirectories corresponding to the initial subdirectories(dir) ie HEALTHY and TUMOR\n",
        "\n",
        "Now randomly choose images from the Subdirectories 1st from Healthy and then from Tumor and os.listdir(full_path) tells us from where we need to pick the data\n",
        "\n",
        "now take 70% of the total images in a subdirectory, we did -5 so that not all the images might get moved to test/train datasets and replace is FALSE it ensures that each image is selected only once\n",
        "\n",
        "Now O is a varibale which hold full path to a particular image and D is a variable which holds full path to our destionation directory\n",
        "\n",
        "By using shutil.copy we copy the image from O to D"
      ],
      "metadata": {
        "id": "4ZVvCSh0v1Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"./train\"):\n",
        "  os.mkdir(\"./train\")\n",
        "  for dir in os.listdir(ROOT_DIR):\n",
        "    os.makedirs(\"./train/\"+dir)\n",
        "    for img in np.random.choice(a=os.listdir(os.path.join(ROOT_DIR,dir)),size= (math.floor(70/100*images[dir])-5),replace=False):\n",
        "      O=os.path.join(ROOT_DIR,dir,img)\n",
        "      D=os.path.join(\"./train\",dir, img)  # Also add the image name to the destination path\n",
        "      shutil.copy(O, D)  # Copy instead of removing\n",
        "else:\n",
        "  print(\"already exist\")\n",
        "\n",
        "if not os.path.exists(\"./test\"):\n",
        "  os.mkdir(\"./test\")\n",
        "  for dir in os.listdir(ROOT_DIR):\n",
        "    os.makedirs(\"./test/\"+dir)\n",
        "    for img in np.random.choice(a=os.listdir(os.path.join(ROOT_DIR,dir)),size= (math.floor(30/100*images[dir])-5),replace=False):\n",
        "      O=os.path.join(ROOT_DIR,dir,img)\n",
        "      D=os.path.join(\"./test\",dir, img)  # Also add the image name to the destination path\n",
        "      shutil.copy(O, D)  # Copy instead of removing\n",
        "else:\n",
        "  print(\"already exist\")"
      ],
      "metadata": {
        "id": "Pwt8fmfm1XxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images={}\n",
        "for dir in os.listdir(ROOT_DIR):\n",
        "    images[dir]=len(os.listdir(os.path.join(ROOT_DIR,dir)))\n",
        "images.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPu1__NwtbXV",
        "outputId": "9512f12b-2a04-4cf8-a9c9-b45fb02beb58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('Tumor', 3516), ('Healthy', 1950)])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have inputed several Layer from Keras\n",
        "\n",
        "CONV2D used processing and detecting/extracting features in 2-dimensional data, such as images\n",
        "\n",
        "MaxPool2D is used to reduce the size of an image by dividing the image into a Matrix and then selecting the max values\n",
        "\n",
        "Dropout is used to avoid overfiting\n",
        "\n",
        "Flatten to convert 2D image to 1D array\n",
        "\n",
        "Dense Layer where each input node is connected to each output node\n",
        "\n",
        "BatchNormalization is used to stabalize the inputs of a neural and train them\n",
        "\n",
        "GlobalAvgPool2D Layer is computes the avg of all the feautures and reduces dimensions to a signle valur per feature\n",
        "\n",
        "Sequential starts building a stack of layers\n",
        "\n",
        " Adam is an optimization algorithm used to train deep learning models\n",
        "\n",
        " ImageDataGenerator used to transform and process the image through dimensions and color"
      ],
      "metadata": {
        "id": "uir-KlQtv7Hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense,BatchNormalization,GlobalAvgPool2D\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "_zKuHX36tjoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "32 filter each of size 3*3 , activation function relu introduces non linearity and we have an u=input shape of 224*224 with three colors RGB\n",
        "\n",
        "Poolin window size if 2*2\n",
        "\n",
        "Dropout layer randomly ignore 50% of neurons in previous layer to avoid overfitting\n",
        "\n",
        "Flatten conerts 2D image to 1D vector\n",
        "\n",
        "128 nuerons in each layer which accepts and send outputs\n",
        "\n",
        "Last layer ie the output layer has 1 nueron\n",
        "\n",
        "Lastly we compile our model with adam as optimizer (optimizer basically adjusts the weight of nueral networks) loss function used for Binary Classification and parameters on which the model will measure its perfromance is accuracy"
      ],
      "metadata": {
        "id": "M3DGVQbSwAwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, BatchNormalization, GlobalAvgPool2D\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPool2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPool2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPool2D((2, 2)),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "L_fMcYyluRmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d80b29-e23f-4f5c-f54a-488a636ac579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 26, 26, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 86528)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               11075712  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11169089 (42.61 MB)\n",
            "Trainable params: 11169089 (42.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augments and prepares images for training by applying transformations like rescaling pixel values, shearing, zooming, and flipping\n",
        "\n",
        "flow from directory tells us the location target size, no of images transfered at a time and binary labels of images"
      ],
      "metadata": {
        "id": "4LNrSumhwEmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "train_data=train_images.flow_from_directory(directory='/content/train',target_size=(224,224),batch_size=32,class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJLG57TnwgSI",
        "outputId": "b8b9d8b5-8590-4f0a-c006-61740e616668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3816 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images=ImageDataGenerator(rescale=1./255)\n",
        "test_data=test_images.flow_from_directory(directory='/content/test',target_size=(224,224),batch_size=32,class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZgINr6px-uq",
        "outputId": "e4490420-a1fa-4a74-c623-eb1e740237c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1629 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EarlyStopping is used to stop training when a monitored metric has stopped improving. This helps prevent overfitting val_accuracy is used to monitor the perfromance of the model, wait for the number of epochs till no improvement\n",
        "\n",
        "ModelCheckPoint saves the model after each epoch and saves the best model only"
      ],
      "metadata": {
        "id": "CxHrn-m5wHHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "es=EarlyStopping(monitor=\"val_accuracy\",patience=5,verbose=1,mode='min')\n",
        "mc=ModelCheckpoint(monitor=\"val_accuracy\",filepath=\"./bestmodel.h5\",verbose=1,save_best_only=True,mode='min')\n",
        "cb=[es,mc]\n"
      ],
      "metadata": {
        "id": "OCedODV314a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use fit method to train out modelwhich trains on train_data and validates the model using test data,epochs =30 means how many times the model will iterate over the dataset and callbacks is used to save the best model"
      ],
      "metadata": {
        "id": "Edw1gkJtwMKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hs = model.fit(\n",
        "    train_data,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    epochs=30,\n",
        "    validation_data=test_data,\n",
        "    validation_steps=len(test_data),\n",
        "    callbacks=cb\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26HiXuQm2ut2",
        "outputId": "d310c68a-4ca8-4bde-f76f-4a6ace227b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "120/120 [==============================] - ETA: 0s - loss: 0.3412 - accuracy: 0.8483\n",
            "Epoch 1: val_accuracy improved from inf to 0.94598, saving model to ./bestmodel.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 500s 4s/step - loss: 0.3412 - accuracy: 0.8483 - val_loss: 0.1654 - val_accuracy: 0.9460\n",
            "Epoch 2/30\n",
            "120/120 [==============================] - ETA: 0s - loss: 0.2088 - accuracy: 0.9201\n",
            "Epoch 2: val_accuracy improved from 0.94598 to 0.89564, saving model to ./bestmodel.h5\n",
            "120/120 [==============================] - 479s 4s/step - loss: 0.2088 - accuracy: 0.9201 - val_loss: 0.2455 - val_accuracy: 0.8956\n",
            "Epoch 3/30\n",
            "120/120 [==============================] - ETA: 0s - loss: 0.1510 - accuracy: 0.9437\n",
            "Epoch 3: val_accuracy did not improve from 0.89564\n",
            "120/120 [==============================] - 478s 4s/step - loss: 0.1510 - accuracy: 0.9437 - val_loss: 0.1096 - val_accuracy: 0.9589\n",
            "Epoch 4/30\n",
            "120/120 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.9486\n",
            "Epoch 4: val_accuracy did not improve from 0.89564\n",
            "120/120 [==============================] - 522s 4s/step - loss: 0.1430 - accuracy: 0.9486 - val_loss: 0.0988 - val_accuracy: 0.9601\n",
            "Epoch 5/30\n",
            "120/120 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9528\n",
            "Epoch 5: val_accuracy improved from 0.89564 to 0.89380, saving model to ./bestmodel.h5\n",
            "120/120 [==============================] - 485s 4s/step - loss: 0.1362 - accuracy: 0.9528 - val_loss: 0.2349 - val_accuracy: 0.8938\n",
            "Epoch 6/30\n",
            "120/120 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9549\n",
            "Epoch 6: val_accuracy did not improve from 0.89380\n",
            "120/120 [==============================] - 470s 4s/step - loss: 0.1174 - accuracy: 0.9549 - val_loss: 0.0992 - val_accuracy: 0.9601\n",
            "Epoch 7/30\n",
            "120/120 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9610\n",
            "Epoch 7: val_accuracy did not improve from 0.89380\n",
            "120/120 [==============================] - 485s 4s/step - loss: 0.1040 - accuracy: 0.9610 - val_loss: 0.0776 - val_accuracy: 0.9681\n",
            "Epoch 8/30\n",
            "120/120 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9631\n",
            "Epoch 8: val_accuracy did not improve from 0.89380\n",
            "120/120 [==============================] - 477s 4s/step - loss: 0.1035 - accuracy: 0.9631 - val_loss: 0.0739 - val_accuracy: 0.9736\n",
            "Epoch 9/30\n",
            "120/120 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9680\n",
            "Epoch 9: val_accuracy did not improve from 0.89380\n",
            "120/120 [==============================] - 483s 4s/step - loss: 0.0812 - accuracy: 0.9680 - val_loss: 0.0668 - val_accuracy: 0.9779\n",
            "Epoch 10/30\n",
            "120/120 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9665\n",
            "Epoch 10: val_accuracy did not improve from 0.89380\n",
            "120/120 [==============================] - 510s 4s/step - loss: 0.0843 - accuracy: 0.9665 - val_loss: 0.0743 - val_accuracy: 0.9730\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accu=model.evaluate(test_data)[1]\n",
        "print(accu)"
      ],
      "metadata": {
        "id": "w7_dOJbEGLDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a1c625-bc49-4674-af66-8c11b35abf40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 60s 1s/step - loss: 0.0743 - accuracy: 0.9730\n",
            "0.972989559173584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model=load_model(\"./bestmodel.h5\")"
      ],
      "metadata": {
        "id": "M-AzxtAXG0x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import load_img,img_to_array\n",
        "path=\"/content/train/Tumor/Te-glTr_0001.jpg\"\n",
        "image=load_img(path,target_size=(224,224))\n",
        "image=img_to_array(image)\n",
        "image=np.expand_dims(image,axis=0)\n",
        "image=image/255\n",
        "pred=model.predict(image)[0][0]\n",
        "if pred > 0.5:  # Adjust the threshold here\n",
        "  print(\"Tumor\")\n",
        "else:\n",
        "  print(\"Healthy\")\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "YcZr9QhTHB5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6906a601-947a-4912-cbf8-f019ed1e319d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n",
            "Tumor\n",
            "0.9855589\n"
          ]
        }
      ]
    }
  ]
}